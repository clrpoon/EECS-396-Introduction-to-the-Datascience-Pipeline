{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ssl\n",
    "try:\n",
    "    _create_unverified_https_context = ssl._create_unverified_context\n",
    "except AttributeError:\n",
    "    pass\n",
    "else:\n",
    "    ssl._create_default_https_context = _create_unverified_https_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cal = datasets.fetch_california_housing()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1. Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a. Evaluate the performance of Linear Regression Model and Gradient Boosting Tree Regression Model on our dataset (use all data and all features) both with default parameters.  Use cross-validation (k =5) to evaluate the performance with r2 scoring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression Fit Score 0.6062326851998049\n",
      "Linear Regression Cross-Validation r2 scores [0.54866323 0.46820691 0.55078434 0.53698703 0.66051406]\n"
     ]
    }
   ],
   "source": [
    "# Linear Regression Model\n",
    "linear_reg = LinearRegression()\n",
    "reg = linear_reg.fit(cal.data, cal.target)\n",
    "print('Linear Regression Fit Score', reg.score(cal.data, cal.target))\n",
    "\n",
    "# Cross validation\n",
    "linear_regression_cv = cross_validate(linear_reg, cal.data, cal.target, cv=5, scoring='r2')\n",
    "print('Linear Regression Cross-Validation r2 scores', linear_regression_cv['test_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Tree Regression Fit Score 0.8033237500356992\n",
      "Gradient Boosting Tree Regression Cross-Validation r2 scores [0.6025313  0.69877396 0.71802327 0.65021286 0.67973314]\n"
     ]
    }
   ],
   "source": [
    "# Gradient Boosting Tree Regression Model\n",
    "gbr = GradientBoostingRegressor()\n",
    "gbr_reg = gbr.fit(cal.data, cal.target)\n",
    "print('Gradient Boosting Tree Regression Fit Score', gbr_reg.score(cal.data, cal.target))\n",
    "\n",
    "# Cross validation\n",
    "gbr_cv = cross_validate(gbr, cal.data, cal.target, cv=5, scoring='r2')\n",
    "print('Gradient Boosting Tree Regression Cross-Validation r2 scores', gbr_cv['test_score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. For the Gradient Boosting Tree,  test different combinations of meta-parameters by grid search. Try to explore number of estimators, depth of the tree and learning rate. Do not try too many combinations of parameters as it can slow down the program significantly (use 4 to 10 combinations is enough in this assignment)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score=nan,\n",
       "             estimator=GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0,\n",
       "                                                 criterion='friedman_mse',\n",
       "                                                 init=None, learning_rate=0.1,\n",
       "                                                 loss='ls', max_depth=3,\n",
       "                                                 max_features=None,\n",
       "                                                 max_leaf_nodes=None,\n",
       "                                                 min_impurity_decrease=0.0,\n",
       "                                                 min_impurity_split=None,\n",
       "                                                 min_samples_leaf=1,\n",
       "                                                 min_samples_split=2,\n",
       "                                                 min_weight_fraction_leaf=0.0,\n",
       "                                                 n_estimators=100,\n",
       "                                                 n_iter_no_change=None,\n",
       "                                                 presort='deprecated',\n",
       "                                                 random_state=None,\n",
       "                                                 subsample=1.0, tol=0.0001,\n",
       "                                                 validation_fraction=0.1,\n",
       "                                                 verbose=0, warm_start=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'learning_rate': [0.1, 1], 'max_depth': [2, 5],\n",
       "                         'n_estimators': [50, 100]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {'learning_rate': [0.1, 1], 'n_estimators': [50, 100], 'max_depth': [2, 5]}\n",
    "grid_search = GridSearchCV(gbr, parameters)\n",
    "grid_search.fit(cal.data, cal.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: {'learning_rate': 0.1, 'max_depth': 2, 'n_estimators': 50}\n",
      "Test Scores: [0.5091085808239103, 0.6047194586660538, 0.6336493568410193, 0.5109309996132647, 0.6116042765322647]\n",
      "Average score: 0.5740025344953026 \n",
      "\n",
      "Parameters: {'learning_rate': 0.1, 'max_depth': 2, 'n_estimators': 100}\n",
      "Test Scores: [0.5666410189218594, 0.6610157103217504, 0.6934111240143579, 0.6302300804653864, 0.6371192859526369]\n",
      "Average score: 0.6376834439351982 \n",
      "\n",
      "Parameters: {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 50}\n",
      "Test Scores: [0.6217386777442604, 0.7001487016079269, 0.7373506111016822, 0.5929473720810241, 0.6793612927704773]\n",
      "Average score: 0.6663093310610743 \n",
      "\n",
      "Parameters: {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 100}\n",
      "Test Scores: [0.623667069100114, 0.708855095326083, 0.7451923585909442, 0.44019395964779795, 0.7096038369805289]\n",
      "Average score: 0.6455024639290936 \n",
      "\n",
      "Parameters: {'learning_rate': 1, 'max_depth': 2, 'n_estimators': 50}\n",
      "Test Scores: [0.5141684560618235, 0.6790427937211255, 0.6821791304304752, 0.4739106557500233, 0.5816017424005754]\n",
      "Average score: 0.5861805556728046 \n",
      "\n",
      "Parameters: {'learning_rate': 1, 'max_depth': 2, 'n_estimators': 100}\n",
      "Test Scores: [0.4947976673229243, 0.6679283867796783, 0.6870157738562199, 0.5174300839297584, 0.5835019921925062]\n",
      "Average score: 0.5901347808162175 \n",
      "\n",
      "Parameters: {'learning_rate': 1, 'max_depth': 5, 'n_estimators': 50}\n",
      "Test Scores: [0.4191888426202711, 0.6074894515314417, 0.585151986705077, 0.05379995230679324, 0.5772293936506172]\n",
      "Average score: 0.44857192536283996 \n",
      "\n",
      "Parameters: {'learning_rate': 1, 'max_depth': 5, 'n_estimators': 100}\n",
      "Test Scores: [0.3830498185465445, 0.5939736365818591, 0.5675443679421561, 0.10540885248135456, 0.5557009927919687]\n",
      "Average score: 0.4411355336687766 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "parameters = grid_search.cv_results_['params']\n",
    "for index in range(0, len(parameters)):\n",
    "    print('Parameters:', parameters[index])\n",
    "    test_scores = [grid_search.cv_results_['split0_test_score'][index], grid_search.cv_results_['split1_test_score'][index],\n",
    "                  grid_search.cv_results_['split2_test_score'][index], grid_search.cv_results_['split3_test_score'][index],\n",
    "                  grid_search.cv_results_['split4_test_score'][index]]\n",
    "    print('Test Scores:', test_scores)\n",
    "    print('Average score:', sum(test_scores) / len(test_scores), '\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c. Briefly discuss the performance and summarize your findings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2. Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a. Evaluate the performance of Logistic Regression Model and Gradient Boosting Tree Classification  Model on our dataset (use all data and all features) both with default parameters. Use cross-validation (k =5) to evaluate the performance with accuracy scoring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/leannahue/Library/Python/3.7/lib/python/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/leannahue/Library/Python/3.7/lib/python/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/leannahue/Library/Python/3.7/lib/python/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/leannahue/Library/Python/3.7/lib/python/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Scores [0.80208333 0.79457364 0.77664729 0.74006783 0.81782946]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/leannahue/Library/Python/3.7/lib/python/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "X = cal.data\n",
    "# set y to 1 if target > 2, 0 otherwise\n",
    "y = 1 * (cal.target > 2)\n",
    "\n",
    "\n",
    "lr = LogisticRegression()\n",
    "# Cross validation\n",
    "LRM_cv = cross_validate(lr, X, y, cv=5)\n",
    "print('Logistic Regression Scores', LRM_cv['test_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Classifier Scores [0.80208333 0.79457364 0.77664729 0.74006783 0.81782946]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "X = cal.data\n",
    "# set y to 1 if target > 2, 0 otherwise\n",
    "y = 1 * (cal.target > 2)\n",
    "\n",
    "\n",
    "gbc = GradientBoostingClassifier()\n",
    "# Cross validation\n",
    "GBC_cv = cross_validate(gbc, X, y, cv=5)\n",
    "print('Gradient Boosting Classifier Scores', LRM_cv['test_score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. For the Gradient Boosting Classification Tree,  test different combinations of meta-parameters by grid search. Try to explore number of estimators, depth of the tree and learning rate. Do not try too many combinations as it can slow down the program significantly. (use 4 to 10 combinations is enough in this assignment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'learning_rate': [0.1, 1], 'n_estimators': [50, 100], 'max_depth': [2, 5]}\n",
    "grid_search_classifier = GridSearchCV(gbr, parameters)\n",
    "grid_search_classifier.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = grid_search.cv_results_['params']\n",
    "for index in range(0, len(parameters)):\n",
    "    print('Parameters:', parameters[index])\n",
    "    test_scores = [grid_search_classifier.cv_results_['split0_test_score'][index], grid_search_classifier.cv_results_['split1_test_score'][index],\n",
    "                  grid_search_classifier.cv_results_['split2_test_score'][index], grid_search_classifier.cv_results_['split3_test_score'][index],\n",
    "                  grid_search_classifier.cv_results_['split4_test_score'][index]]\n",
    "    print('Test Scores:', test_scores)\n",
    "    print('Average score:', sum(test_scores) / len(test_scores), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c. Repeat the above (a and b) steps for using Area Under the Receiver Operating Characteristic Curve (ROC AUC) as the scoring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a\n",
    "# Logistic Regression\n",
    "lr = LogisticRegression()\n",
    "LRM_cv = cross_validate(lr, X, y, cv=5, scoring='roc_auc')\n",
    "print('Logistic Regression ROC AUC Scores', LRM_cv['test_score'])\n",
    "\n",
    "# Gradient Boosting Classifier\n",
    "gbc = GradientBoostingClassifier()\n",
    "# Cross validation\n",
    "GBC_cv = cross_validate(gbc, X, y, cv=5, scoring='roc_auc')\n",
    "print('Gradient Boosting Classifier Scores', LRM_cv['test_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# b\n",
    "parameters = {'learning_rate': [0.1, 1], 'n_estimators': [50, 100], 'max_depth': [2, 5]}\n",
    "grid_search_classifier = GridSearchCV(gbr, parameters, scoring='roc_auc')\n",
    "grid_search_classifier.fit(X, y)\n",
    "\n",
    "parameters = grid_search.cv_results_['params']\n",
    "for index in range(0, len(parameters)):\n",
    "    print('Parameters:', parameters[index])\n",
    "    test_scores = [grid_search_classifier.cv_results_['split0_test_score'][index], grid_search_classifier.cv_results_['split1_test_score'][index],\n",
    "                  grid_search_classifier.cv_results_['split2_test_score'][index], grid_search_classifier.cv_results_['split3_test_score'][index],\n",
    "                  grid_search_classifier.cv_results_['split4_test_score'][index]]\n",
    "    print('Test Scores:', test_scores)\n",
    "    print('Average score:', sum(test_scores) / len(test_scores), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
